{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5el_8SqFqVAT"
   },
   "source": [
    "\n",
    "In this notebook, You will do amazon review classification with BERT.[Download data from [this](https://www.kaggle.com/snap/amazon-fine-food-reviews/data) link]\n",
    "<pre> \n",
    "It contains 5 parts as below.  Detailed instrctions are given in the each cell. please read every comment we have written. \n",
    "    1. Preprocessing \n",
    "    2. Creating a BERT model from the Tensorflow HUB.\n",
    "    3. Tokenization\n",
    "    4. getting the pretrained embedding Vector for a given review from the BERT.\n",
    "    5. Using the embedding data apply NN and classify the reviews.\n",
    "    6. Creating a Data pipeline for BERT Model. \n",
    "\n",
    "<font size=5>instructions:</font>\n",
    "\n",
    "    1. Don't change any Grader Functions. Don't manipulate any Grader functions. \n",
    "    If you manipulate any, it will be considered as plagiarised. \n",
    "    \n",
    "    2. Please read the instructions on the code cells and markdown cells. We will explain what to write. \n",
    "    \n",
    "    3. please return outputs in the same format what we asked. Eg. Don't return List if we are asking for a numpy array.\n",
    "    \n",
    "    4. Please read the external links that we are given so that you will learn the concept behind the code that you are writing.\n",
    "    \n",
    "    5. We are giving instructions at each section if necessary, please follow them. \n",
    "\n",
    "<font size=5>Every Grader function has to return True. </font>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SsoIxOc4bjRM"
   },
   "outputs": [],
   "source": [
    "!mkdir ~/.kaggle\n",
    "! cp kaggle.json ~/.kaggle/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BTHaqQDncM3T"
   },
   "outputs": [],
   "source": [
    "! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-gCCsoSxcUpL",
    "outputId": "04923022-c361-4e60-db0b-fa594a3dffe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon-fine-food-reviews.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "! kaggle datasets download -d snap/amazon-fine-food-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NtimD3BzciJ7",
    "outputId": "7a33429b-b28f-4bb8-94fd-d976c4c888a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  amazon-fine-food-reviews.zip\n",
      "  inflating: Reviews.csv             \n",
      "  inflating: database.sqlite         \n",
      "  inflating: hashes.txt              \n"
     ]
    }
   ],
   "source": [
    " ! unzip amazon-fine-food-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wOtG4cf0qVAZ"
   },
   "outputs": [],
   "source": [
    "#all imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "OcmiHdAJqVAi",
    "outputId": "256fed2a-55d5-4ef1-fc35-19c3c69f0b5f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBsay58AqVAo"
   },
   "source": [
    "<font size=4>Grader function 1 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aTBvOKFeqVAq",
    "outputId": "73f01208-5396-406d-cec1-c751700a0c76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_tf_version():\n",
    "    assert((tf.__version__)>'2')\n",
    "    return True\n",
    "grader_tf_version()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTWRqbrBqVAu"
   },
   "source": [
    "<pre><font size=6>Part-1: Preprocessing</font></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B3csZKDrqVAv",
    "outputId": "10f01b13-249a-4342-9f7b-f3954dc006ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568454 entries, 0 to 568453\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   Id                      568454 non-null  int64 \n",
      " 1   ProductId               568454 non-null  object\n",
      " 2   UserId                  568454 non-null  object\n",
      " 3   ProfileName             568438 non-null  object\n",
      " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
      " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
      " 6   Score                   568454 non-null  int64 \n",
      " 7   Time                    568454 non-null  int64 \n",
      " 8   Summary                 568427 non-null  object\n",
      " 9   Text                    568454 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 43.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#Read the dataset - Amazon fine food reviews\n",
    "reviews = pd.read_csv(r\"Reviews.csv\")\n",
    "#check the info of the dataset\n",
    "reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5GZt7pVkqVA4"
   },
   "outputs": [],
   "source": [
    "#if score> 3, set score = 1\n",
    "#if score<=2, set score = 0\n",
    "#if score == 3, remove the rows. \n",
    "reviews = reviews[reviews['Score']!=3][['Text', 'Score']].dropna()\n",
    "reviews['Score'] = np.where(reviews.Score>3, 1, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVe8LlkrqVA6"
   },
   "source": [
    "<font size=4>Grader function 2 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7mDXSiJpqVA7",
    "outputId": "180f992b-35cb-4c53-993f-8d34380a026e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_reviews():\n",
    "    temp_shape = (reviews.shape == (525814, 2)) and (reviews.Score.value_counts()[1]==443777)\n",
    "    assert(temp_shape == True)\n",
    "    return True\n",
    "grader_reviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xYZ-UB9UqVA-"
   },
   "outputs": [],
   "source": [
    "def get_wordlen(x):\n",
    "    return len(x.split())\n",
    "reviews['len'] = reviews.Text.apply(get_wordlen)\n",
    "reviews = reviews[reviews.len<50]\n",
    "reviews = reviews.sample(n=100000, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "CvldQriGqVBB"
   },
   "outputs": [],
   "source": [
    "#remove HTML from the Text column and save in the Text column only\n",
    "import re\n",
    "reviews['Text'] = reviews['Text'].apply(lambda x : re.sub('<.*?>','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "AhfN1s2mqVBD",
    "outputId": "38f4ab33-6144-4de8-f042-0d9c7117b095"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64117</th>\n",
       "      <td>The tea was of great quality and it tasted lik...</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418112</th>\n",
       "      <td>My cat loves this.  The pellets are nice and s...</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357829</th>\n",
       "      <td>Great product. Does not completely get rid of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175872</th>\n",
       "      <td>This gum is my favorite!  I would advise every...</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178716</th>\n",
       "      <td>I also found out about this product because of...</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  Score  len\n",
       "64117   The tea was of great quality and it tasted lik...      1   30\n",
       "418112  My cat loves this.  The pellets are nice and s...      1   31\n",
       "357829  Great product. Does not completely get rid of ...      1   41\n",
       "175872  This gum is my favorite!  I would advise every...      1   27\n",
       "178716  I also found out about this product because of...      1   22"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print head 5\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "NsYDd3okqVBF"
   },
   "outputs": [],
   "source": [
    "#split the data into train and test data(20%) with Stratify sampling, random state 33, \n",
    "from sklearn.model_selection import train_test_split\n",
    "X = reviews.drop(['Score'], axis=1)\n",
    "y = reviews['Score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y,random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "KAEWk84mxdNJ",
    "outputId": "0ae3a60e-9ccb-4c1d-87df-acd4b791f22c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcad7a4cf90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train.value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "8q_37xkbxJHF",
    "outputId": "041c877f-a8ad-4cfc-d867-7a18f0b61136"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcaea263150>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test.value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Up-z5boWqVBK"
   },
   "outputs": [],
   "source": [
    "#saving to disk. if we need, we can load preprocessed data directly. \n",
    "reviews.to_csv('preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBtqNGN9qVBM"
   },
   "source": [
    "<pre><font size=6>Part-2: Creating BERT Model</font> \n",
    "\n",
    "If you want to know more about BERT, You can watch live sessions on Transformers and BERt. \n",
    "we will strongly recommend you to read <a href=\"https://jalammar.github.io/illustrated-transformer/\">Transformers</a>, <a href=\"https://arxiv.org/abs/1810.04805\">BERT Paper</a> and, <a href=\"https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/\">This blog</a>.\n",
    "\n",
    "\n",
    "For this assignment, we are using <a href=\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\">BERT uncased Base model</a>. \n",
    "It uses L=12 hidden layers (i.e., Transformer blocks), a hidden size of H=768, and A=12 attention heads. </pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "i8xd2HejqVBN"
   },
   "outputs": [],
   "source": [
    "## Loading the Pretrained Model from tensorflow HUB\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# maximum length of a seq in the data we have, for now i am making it as 55. You can change this\n",
    "max_seq_length = 55\n",
    "\n",
    "#BERT takes 3 inputs\n",
    "\n",
    "#this is input words. Sequence of words represented as integers\n",
    "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "\n",
    "#mask vector if you are padding anything\n",
    "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n",
    "\n",
    "#segment vectors. If you are giving only one sentence for the classification, total seg vector is 0. \n",
    "#If you are giving two sentenced with [sep] token separated, first seq segment vectors are zeros and \n",
    "#second seq segment vector are 1's\n",
    "segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"segment_ids\")\n",
    "\n",
    "#bert layer \n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\", trainable=False)\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "\n",
    "#Bert model\n",
    "#We are using only pooled output not sequence out. \n",
    "#If you want to know about those, please read https://www.kaggle.com/questions-and-answers/86510\n",
    "bert_model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=pooled_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lQJsjg6fqVBQ",
    "outputId": "1f197244-1ff2-4df5-dcd6-28d0365eb83e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, None, 768])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w3z0OMA5qVBS",
    "outputId": "d4a68293-fb6c-4218-b705-c2e09b33b79c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'keras_layer')>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ewv4hFCsqVBU"
   },
   "source": [
    "<pre><font size=6>Part-3: Tokenization</font></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tX3VEFjiqVBU"
   },
   "outputs": [],
   "source": [
    "#getting Vocab file\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AtsL9yWq2Lr6",
    "outputId": "2524d482-ee79-42c5-ace1-2978c5825c3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'/tmp/tfhub_modules/03d6fb3ce1605ad9e5e9ed5346b2fb9623ef4d3d/assets/vocab.txt'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Y_iPwa99qVBW"
   },
   "outputs": [],
   "source": [
    "#import tokenization - We have given tokenization.py file\n",
    "\"\"\"Tokenization classes.\"\"\"\n",
    "#This code snippet has been copied from github\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import re\n",
    "import unicodedata\n",
    "import six\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def validate_case_matches_checkpoint(do_lower_case, init_checkpoint):\n",
    "  \"\"\"Checks whether the casing config is consistent with the checkpoint name.\"\"\"\n",
    "\n",
    "  # The casing has to be passed in by the user and there is no explicit check\n",
    "  # as to whether it matches the checkpoint. The casing information probably\n",
    "  # should have been stored in the bert_config.json file, but it's not, so\n",
    "  # we have to heuristically detect it to validate.\n",
    "\n",
    "  if not init_checkpoint:\n",
    "    return\n",
    "\n",
    "  m = re.match(\"^.*?([A-Za-z0-9_-]+)/bert_model.ckpt\", init_checkpoint)\n",
    "  if m is None:\n",
    "    return\n",
    "\n",
    "  model_name = m.group(1)\n",
    "\n",
    "  lower_models = [\n",
    "      \"uncased_L-24_H-1024_A-16\", \"uncased_L-12_H-768_A-12\",\n",
    "      \"multilingual_L-12_H-768_A-12\", \"chinese_L-12_H-768_A-12\"\n",
    "  ]\n",
    "\n",
    "  cased_models = [\n",
    "      \"cased_L-12_H-768_A-12\", \"cased_L-24_H-1024_A-16\",\n",
    "      \"multi_cased_L-12_H-768_A-12\"\n",
    "  ]\n",
    "\n",
    "  is_bad_config = False\n",
    "  if model_name in lower_models and not do_lower_case:\n",
    "    is_bad_config = True\n",
    "    actual_flag = \"False\"\n",
    "    case_name = \"lowercased\"\n",
    "    opposite_flag = \"True\"\n",
    "\n",
    "  if model_name in cased_models and do_lower_case:\n",
    "    is_bad_config = True\n",
    "    actual_flag = \"True\"\n",
    "    case_name = \"cased\"\n",
    "    opposite_flag = \"False\"\n",
    "\n",
    "  if is_bad_config:\n",
    "    raise ValueError(\n",
    "        \"You passed in `--do_lower_case=%s` with `--init_checkpoint=%s`. \"\n",
    "        \"However, `%s` seems to be a %s model, so you \"\n",
    "        \"should pass in `--do_lower_case=%s` so that the fine-tuning matches \"\n",
    "        \"how the model was pre-training. If this error is wrong, please \"\n",
    "        \"just comment out this check.\" % (actual_flag, init_checkpoint,\n",
    "                                          model_name, case_name, opposite_flag))\n",
    "\n",
    "\n",
    "def convert_to_unicode(text):\n",
    "  \"\"\"Converts `text` to Unicode (if it's not already), assuming utf-8 input.\"\"\"\n",
    "  if six.PY3:\n",
    "    if isinstance(text, str):\n",
    "      return text\n",
    "    elif isinstance(text, bytes):\n",
    "      return text.decode(\"utf-8\", \"ignore\")\n",
    "    else:\n",
    "      raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
    "  elif six.PY2:\n",
    "    if isinstance(text, str):\n",
    "      return text.decode(\"utf-8\", \"ignore\")\n",
    "    elif isinstance(text, unicode):\n",
    "      return text\n",
    "    else:\n",
    "      raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
    "  else:\n",
    "    raise ValueError(\"Not running on Python2 or Python 3?\")\n",
    "\n",
    "\n",
    "def printable_text(text):\n",
    "  \"\"\"Returns text encoded in a way suitable for print or `tf.logging`.\"\"\"\n",
    "\n",
    "  # These functions want `str` for both Python2 and Python3, but in one case\n",
    "  # it's a Unicode string and in the other it's a byte string.\n",
    "  if six.PY3:\n",
    "    if isinstance(text, str):\n",
    "      return text\n",
    "    elif isinstance(text, bytes):\n",
    "      return text.decode(\"utf-8\", \"ignore\")\n",
    "    else:\n",
    "      raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
    "  elif six.PY2:\n",
    "    if isinstance(text, str):\n",
    "      return text\n",
    "    elif isinstance(text, unicode):\n",
    "      return text.encode(\"utf-8\")\n",
    "    else:\n",
    "      raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
    "  else:\n",
    "    raise ValueError(\"Not running on Python2 or Python 3?\")\n",
    "\n",
    "\n",
    "def load_vocab(vocab_file):\n",
    "  \"\"\"Loads a vocabulary file into a dictionary.\"\"\"\n",
    "  vocab = collections.OrderedDict()\n",
    "  index = 0\n",
    "  with tf.io.gfile.GFile(vocab_file, \"r\") as reader:\n",
    "    while True:\n",
    "      token = convert_to_unicode(reader.readline())\n",
    "      if not token:\n",
    "        break\n",
    "      token = token.strip()\n",
    "      vocab[token] = index\n",
    "      index += 1\n",
    "  return vocab\n",
    "\n",
    "\n",
    "def convert_by_vocab(vocab, items):\n",
    "  \"\"\"Converts a sequence of [tokens|ids] using the vocab.\"\"\"\n",
    "  output = []\n",
    "  for item in items:\n",
    "    output.append(vocab[item])\n",
    "  return output\n",
    "\n",
    "\n",
    "def convert_tokens_to_ids(vocab, tokens):\n",
    "  return convert_by_vocab(vocab, tokens)\n",
    "\n",
    "\n",
    "def convert_ids_to_tokens(inv_vocab, ids):\n",
    "  return convert_by_vocab(inv_vocab, ids)\n",
    "\n",
    "\n",
    "def whitespace_tokenize(text):\n",
    "  \"\"\"Runs basic whitespace cleaning and splitting on a piece of text.\"\"\"\n",
    "  text = text.strip()\n",
    "  if not text:\n",
    "    return []\n",
    "  tokens = text.split()\n",
    "  return tokens\n",
    "\n",
    "\n",
    "class FullTokenizer(object):\n",
    "  \"\"\"Runs end-to-end tokenziation.\"\"\"\n",
    "\n",
    "  def __init__(self, vocab_file, do_lower_case=True):\n",
    "    self.vocab = load_vocab(vocab_file)\n",
    "    self.inv_vocab = {v: k for k, v in self.vocab.items()}\n",
    "    self.basic_tokenizer = BasicTokenizer(do_lower_case=do_lower_case)\n",
    "    self.wordpiece_tokenizer = WordpieceTokenizer(vocab=self.vocab)\n",
    "\n",
    "  def tokenize(self, text):\n",
    "    split_tokens = []\n",
    "    for token in self.basic_tokenizer.tokenize(text):\n",
    "      for sub_token in self.wordpiece_tokenizer.tokenize(token):\n",
    "        split_tokens.append(sub_token)\n",
    "\n",
    "    return split_tokens\n",
    "\n",
    "  def convert_tokens_to_ids(self, tokens):\n",
    "    return convert_by_vocab(self.vocab, tokens)\n",
    "\n",
    "  def convert_ids_to_tokens(self, ids):\n",
    "    return convert_by_vocab(self.inv_vocab, ids)\n",
    "\n",
    "\n",
    "class BasicTokenizer(object):\n",
    "  \"\"\"Runs basic tokenization (punctuation splitting, lower casing, etc.).\"\"\"\n",
    "\n",
    "  def __init__(self, do_lower_case=True):\n",
    "    \"\"\"Constructs a BasicTokenizer.\n",
    "    Args:\n",
    "      do_lower_case: Whether to lower case the input.\n",
    "    \"\"\"\n",
    "    self.do_lower_case = do_lower_case\n",
    "\n",
    "  def tokenize(self, text):\n",
    "    \"\"\"Tokenizes a piece of text.\"\"\"\n",
    "    text = convert_to_unicode(text)\n",
    "    text = self._clean_text(text)\n",
    "\n",
    "\n",
    "    # This was added on November 1st, 2018 for the multilingual and Chinese\n",
    "    # models. This is also applied to the English models now, but it doesn't\n",
    "    # matter since the English models were not trained on any Chinese data\n",
    "    # and generally don't have any Chinese data in them (there are Chinese\n",
    "    # characters in the vocabulary because Wikipedia does have some Chinese\n",
    "    # words in the English Wikipedia.).\n",
    "    text = self._tokenize_chinese_chars(text)\n",
    "\n",
    "    orig_tokens = whitespace_tokenize(text)\n",
    "    split_tokens = []\n",
    "    for token in orig_tokens:\n",
    "      if self.do_lower_case:\n",
    "        token = token.lower()\n",
    "        token = self._run_strip_accents(token)\n",
    "      split_tokens.extend(self._run_split_on_punc(token))\n",
    "\n",
    "    output_tokens = whitespace_tokenize(\" \".join(split_tokens))\n",
    "    return output_tokens\n",
    "\n",
    "  def _run_strip_accents(self, text):\n",
    "    \"\"\"Strips accents from a piece of text.\"\"\"\n",
    "    text = unicodedata.normalize(\"NFD\", text)\n",
    "    output = []\n",
    "    for char in text:\n",
    "      cat = unicodedata.category(char)\n",
    "      if cat == \"Mn\":\n",
    "        continue\n",
    "      output.append(char)\n",
    "    return \"\".join(output)\n",
    "\n",
    "  def _run_split_on_punc(self, text):\n",
    "    \"\"\"Splits punctuation on a piece of text.\"\"\"\n",
    "    chars = list(text)\n",
    "    i = 0\n",
    "    start_new_word = True\n",
    "    output = []\n",
    "    while i < len(chars):\n",
    "      char = chars[i]\n",
    "      if _is_punctuation(char):\n",
    "        output.append([char])\n",
    "        start_new_word = True\n",
    "      else:\n",
    "        if start_new_word:\n",
    "          output.append([])\n",
    "        start_new_word = False\n",
    "        output[-1].append(char)\n",
    "      i += 1\n",
    "\n",
    "    return [\"\".join(x) for x in output]\n",
    "\n",
    "  def _tokenize_chinese_chars(self, text):\n",
    "    \"\"\"Adds whitespace around any CJK character.\"\"\"\n",
    "    output = []\n",
    "    for char in text:\n",
    "      cp = ord(char)\n",
    "      if self._is_chinese_char(cp):\n",
    "        output.append(\" \")\n",
    "        output.append(char)\n",
    "        output.append(\" \")\n",
    "      else:\n",
    "        output.append(char)\n",
    "    return \"\".join(output)\n",
    "\n",
    "  def _is_chinese_char(self, cp):\n",
    "    \"\"\"Checks whether CP is the codepoint of a CJK character.\"\"\"\n",
    "    # This defines a \"chinese character\" as anything in the CJK Unicode block:\n",
    "    #   https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)\n",
    "    #\n",
    "    # Note that the CJK Unicode block is NOT all Japanese and Korean characters,\n",
    "    # despite its name. The modern Korean Hangul alphabet is a different block,\n",
    "    # as is Japanese Hiragana and Katakana. Those alphabets are used to write\n",
    "    # space-separated words, so they are not treated specially and handled\n",
    "    # like the all of the other languages.\n",
    "    if ((cp >= 0x4E00 and cp <= 0x9FFF) or  #\n",
    "        (cp >= 0x3400 and cp <= 0x4DBF) or  #\n",
    "        (cp >= 0x20000 and cp <= 0x2A6DF) or  #\n",
    "        (cp >= 0x2A700 and cp <= 0x2B73F) or  #\n",
    "        (cp >= 0x2B740 and cp <= 0x2B81F) or  #\n",
    "        (cp >= 0x2B820 and cp <= 0x2CEAF) or\n",
    "        (cp >= 0xF900 and cp <= 0xFAFF) or  #\n",
    "        (cp >= 0x2F800 and cp <= 0x2FA1F)):  #\n",
    "      return True\n",
    "\n",
    "    return False\n",
    "\n",
    "  def _clean_text(self, text):\n",
    "    \"\"\"Performs invalid character removal and whitespace cleanup on text.\"\"\"\n",
    "    output = []\n",
    "    for char in text:\n",
    "      cp = ord(char)\n",
    "      if cp == 0 or cp == 0xfffd or _is_control(char):\n",
    "        continue\n",
    "      if _is_whitespace(char):\n",
    "        output.append(\" \")\n",
    "      else:\n",
    "        output.append(char)\n",
    "    return \"\".join(output)\n",
    "\n",
    "\n",
    "class WordpieceTokenizer(object):\n",
    "  \"\"\"Runs WordPiece tokenziation.\"\"\"\n",
    "\n",
    "  def __init__(self, vocab, unk_token=\"[UNK]\", max_input_chars_per_word=200):\n",
    "    self.vocab = vocab\n",
    "    self.unk_token = unk_token\n",
    "    self.max_input_chars_per_word = max_input_chars_per_word\n",
    "\n",
    "  def tokenize(self, text):\n",
    "    \"\"\"Tokenizes a piece of text into its word pieces.\n",
    "    This uses a greedy longest-match-first algorithm to perform tokenization\n",
    "    using the given vocabulary.\n",
    "    For example:\n",
    "      input = \"unaffable\"\n",
    "      output = [\"un\", \"##aff\", \"##able\"]\n",
    "    Args:\n",
    "      text: A single token or whitespace separated tokens. This should have\n",
    "        already been passed through `BasicTokenizer.\n",
    "    Returns:\n",
    "      A list of wordpiece tokens.\n",
    "    \"\"\"\n",
    "\n",
    "    text = convert_to_unicode(text)\n",
    "\n",
    "    output_tokens = []\n",
    "    for token in whitespace_tokenize(text):\n",
    "      chars = list(token)\n",
    "      if len(chars) > self.max_input_chars_per_word:\n",
    "        output_tokens.append(self.unk_token)\n",
    "        continue\n",
    "\n",
    "      is_bad = False\n",
    "      start = 0\n",
    "      sub_tokens = []\n",
    "      while start < len(chars):\n",
    "        end = len(chars)\n",
    "        cur_substr = None\n",
    "        while start < end:\n",
    "          substr = \"\".join(chars[start:end])\n",
    "          if start > 0:\n",
    "            substr = \"##\" + substr\n",
    "          if substr in self.vocab:\n",
    "            cur_substr = substr\n",
    "            break\n",
    "          end -= 1\n",
    "        if cur_substr is None:\n",
    "          is_bad = True\n",
    "          break\n",
    "        sub_tokens.append(cur_substr)\n",
    "        start = end\n",
    "\n",
    "      if is_bad:\n",
    "        output_tokens.append(self.unk_token)\n",
    "      else:\n",
    "        output_tokens.extend(sub_tokens)\n",
    "    return output_tokens\n",
    "\n",
    "\n",
    "def _is_whitespace(char):\n",
    "  \"\"\"Checks whether `chars` is a whitespace character.\"\"\"\n",
    "  # \\t, \\n, and \\r are technically contorl characters but we treat them\n",
    "  # as whitespace since they are generally considered as such.\n",
    "  if char == \" \" or char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
    "    return True\n",
    "  cat = unicodedata.category(char)\n",
    "  if cat == \"Zs\":\n",
    "    return True\n",
    "  return False\n",
    "\n",
    "\n",
    "def _is_control(char):\n",
    "  \"\"\"Checks whether `chars` is a control character.\"\"\"\n",
    "  # These are technically control characters but we count them as whitespace\n",
    "  # characters.\n",
    "  if char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
    "    return False\n",
    "  cat = unicodedata.category(char)\n",
    "  if cat in (\"Cc\", \"Cf\"):\n",
    "    return True\n",
    "  return False\n",
    "\n",
    "\n",
    "def _is_punctuation(char):\n",
    "  \"\"\"Checks whether `chars` is a punctuation character.\"\"\"\n",
    "  cp = ord(char)\n",
    "  # We treat all non-letter/number ASCII as punctuation.\n",
    "  # Characters such as \"^\", \"$\", and \"`\" are not in the Unicode\n",
    "  # Punctuation class but we treat them as punctuation anyways, for\n",
    "  # consistency.\n",
    "  if ((cp >= 33 and cp <= 47) or (cp >= 58 and cp <= 64) or\n",
    "      (cp >= 91 and cp <= 96) or (cp >= 123 and cp <= 126)):\n",
    "    return True\n",
    "  cat = unicodedata.category(char)\n",
    "  if cat.startswith(\"P\"):\n",
    "    return True\n",
    "  return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "guJMLJ8bqVBY"
   },
   "outputs": [],
   "source": [
    "# Create tokenizer \" Instantiate FullTokenizer\" \n",
    "# name must be \"tokenizer\"\n",
    "# the FullTokenizer takes two parameters 1. vocab_file and 2. do_lower_case \n",
    "# we have created these in the above cell ex: FullTokenizer(vocab_file, do_lower_case )\n",
    "# please check the \"tokenization.py\" file the complete implementation\n",
    "tokenizer = FullTokenizer(vocab_file, do_lower_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKkGLhR-qVBd"
   },
   "source": [
    "<font size=4>Grader function 3 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2CPu850xqVBe",
    "outputId": "697d7f05-d6ed-4234-f9f5-53072f96bf3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#it has to give no error \n",
    "def grader_tokenize(tokenizer):\n",
    "    out = False\n",
    "    try:\n",
    "        out=('[CLS]' in tokenizer.vocab) and ('[SEP]' in tokenizer.vocab)\n",
    "    except:\n",
    "        out = False\n",
    "    assert(out==True)\n",
    "    return out\n",
    "grader_tokenize(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9crhPylQqVBg"
   },
   "outputs": [],
   "source": [
    "# Create train and test tokens (X_train_tokens, X_test_tokens) from (X_train, X_test) using Tokenizer and \n",
    "\n",
    "# add '[CLS]' at start of the Tokens and '[SEP]' at the end of the tokens. \n",
    "\n",
    "# maximum number of tokens is 55(We already given this to BERT layer above) so shape is (None, 55)\n",
    "\n",
    "# if it is less than 55, add '[PAD]' token else truncate the tokens length.(similar to padding)\n",
    "\n",
    "# Based on padding, create the mask for Train and Test ( 1 for real token, 0 for '[PAD]'), \n",
    "# it will also same shape as input tokens (None, 55) save those in X_train_mask, X_test_mask\n",
    "\n",
    "# Create a segment input for train and test. We are using only one sentence so all zeros. This shape will also (None, 55)\n",
    "\n",
    "# type of all the above arrays should be numpy arrays\n",
    "\n",
    "# after execution of this cell, you have to get \n",
    "# X_train_tokens, X_train_mask, X_train_segment\n",
    "# X_test_tokens, X_test_mask, X_test_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qXDzY1P_5Bmc"
   },
   "outputs": [],
   "source": [
    "#tokenized = reviews['Text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RJyzreCyeaUA",
    "outputId": "949ac07e-2b1c-4f49-a33a-7d4b9b9b897c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80000/80000 [00:55<00:00, 1453.75it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tokenized_id_train = []\n",
    "padded_list_train = []\n",
    "segment_list_train = []\n",
    "for review in tqdm((X_train['Text'])):\n",
    "        tokens = tokenizer.tokenize(review)\n",
    "        tokens = ['[CLS]', *tokens, '[SEP]']\n",
    "        # ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        # ids = [ int(x) for x in ids ]\n",
    "        #tokenized_id_train.append(ids)\n",
    "        if len(tokens)<=max_seq_length: \n",
    "          #padding with [PAD]\n",
    "            padded = tokens+['[PAD]' for i in range(max_seq_length - len(tokens))]\n",
    "        ids = tokenizer.convert_tokens_to_ids(padded)\n",
    "        ids = [ int(x) for x in ids ]\n",
    "        padded_list_train.append(ids)\n",
    "        segment = np.zeros(max_seq_length, dtype = int)\n",
    "        segment_list_train.append(segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zUTWXnWRn5EC",
    "outputId": "abaf8b8d-c754-4ec1-f299-1e18ee9430cf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:13<00:00, 1469.13it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_id_test = []\n",
    "padded_list_test = []\n",
    "segment_list_test = []\n",
    "for review in tqdm((X_test['Text'])):\n",
    "        tokens = tokenizer.tokenize(review)\n",
    "        tokens = ['[CLS]', *tokens, '[SEP]']\n",
    "        # ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        # ids = [ int(x) for x in ids ]\n",
    "        # tokenized_id_test.append(ids)\n",
    "        if len(tokens)<=max_seq_length: \n",
    "          #padding with [PAD]\n",
    "            padded = tokens+['[PAD]' for i in range(max_seq_length - len(tokens))]\n",
    "        ids = tokenizer.convert_tokens_to_ids(padded)\n",
    "        ids = [ int(x) for x in ids ]\n",
    "        padded_list_test.append(ids)\n",
    "        segment = np.zeros(max_seq_length, dtype = int)\n",
    "        segment_list_test.append(segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6SB3xlCckZFq"
   },
   "outputs": [],
   "source": [
    "##np.array(padded_list)\n",
    "attention_mask_train = np.where(np.array(padded_list_train) != [0], 1, 0)\n",
    "attention_mask_test = np.where(np.array(padded_list_test) != [0], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "wYgB-9mttaIl"
   },
   "outputs": [],
   "source": [
    "X_train_tokens, X_train_mask, X_train_segment = np.array(padded_list_train),np.array(attention_mask_train),np.array(segment_list_train)\n",
    "X_test_tokens, X_test_mask, X_test_segment = np.array(padded_list_test),np.array(attention_mask_test),np.array(segment_list_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kv1-t4OjqVBj"
   },
   "source": [
    "#### Example\n",
    "<img src='https://i.imgur.com/5AhhmgU.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dxhggBxwqVBj"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xF0idMRDqVBm"
   },
   "outputs": [],
   "source": [
    "##save all your results to disk so that, no need to run all again. \n",
    "pickle.dump((X_train, X_train_tokens, X_train_mask, X_train_segment, y_train),open('train_data.pkl','wb'))\n",
    "pickle.dump((X_test, X_test_tokens, X_test_mask, X_test_segment, y_test),open('test_data.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Leu1URGzqVBo"
   },
   "outputs": [],
   "source": [
    "#you can load from disk\n",
    "#X_train, X_train_tokens, X_train_mask, X_train_segment, y_train = pickle.load(open(\"train_data.pkl\", 'rb')) \n",
    "#X_test, X_test_tokens, X_test_mask, X_test_segment, y_test = pickle.load(open(\"test_data.pkl\", 'rb')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjPv8VkJqVBr"
   },
   "source": [
    "<font size=4>Grader function 4 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qekHJgmdqVBs",
    "outputId": "7b0e0d14-3fab-4231-d030-672edd42a537"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_alltokens_train():\n",
    "    out = False\n",
    "    \n",
    "    if type(X_train_tokens) == np.ndarray:\n",
    "        \n",
    "        temp_shapes = (X_train_tokens.shape[1]==max_seq_length) and (X_train_mask.shape[1]==max_seq_length) and \\\n",
    "        (X_train_segment.shape[1]==max_seq_length)\n",
    "        \n",
    "        segment_temp = not np.any(X_train_segment)\n",
    "        \n",
    "        mask_temp = np.sum(X_train_mask==0) == np.sum(X_train_tokens==0)\n",
    "        \n",
    "        no_cls = np.sum(X_train_tokens==tokenizer.vocab['[CLS]'])==X_train_tokens.shape[0]\n",
    "        \n",
    "        no_sep = np.sum(X_train_tokens==tokenizer.vocab['[SEP]'])==X_train_tokens.shape[0]\n",
    "        \n",
    "        out = temp_shapes and segment_temp and mask_temp and no_cls and no_sep\n",
    "      \n",
    "    else:\n",
    "        print('Type of all above token arrays should be numpy array not list')\n",
    "        out = False\n",
    "    assert(out==True)\n",
    "    return out\n",
    "\n",
    "grader_alltokens_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnvC6X_wqVBu"
   },
   "source": [
    "<font size=4>Grader function 5 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Av4SRMPSqVBv",
    "outputId": "06ca58a8-164a-42c2-84c2-f9024898071e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_alltokens_test():\n",
    "    out = False\n",
    "    if type(X_test_tokens) == np.ndarray:\n",
    "        \n",
    "        temp_shapes = (X_test_tokens.shape[1]==max_seq_length) and (X_test_mask.shape[1]==max_seq_length) and \\\n",
    "        (X_test_segment.shape[1]==max_seq_length)\n",
    "        \n",
    "        segment_temp = not np.any(X_test_segment)\n",
    "        \n",
    "        mask_temp = np.sum(X_test_mask==0) == np.sum(X_test_tokens==0)\n",
    "        \n",
    "        no_cls = np.sum(X_test_tokens==tokenizer.vocab['[CLS]'])==X_test_tokens.shape[0]\n",
    "        \n",
    "        no_sep = np.sum(X_test_tokens==tokenizer.vocab['[SEP]'])==X_test_tokens.shape[0]\n",
    "        \n",
    "        out = temp_shapes and segment_temp and mask_temp and no_cls and no_sep\n",
    "      \n",
    "    else:\n",
    "        print('Type of all above token arrays should be numpy array not list')\n",
    "        out = False\n",
    "    assert(out==True)\n",
    "    return out\n",
    "grader_alltokens_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEj-Eua5qVBx"
   },
   "source": [
    "<pre><font size=6>Part-4: Getting Embeddings from BERT Model</font>\n",
    "We already created the BERT model in the part-2 and input data in the part-3. \n",
    "We will utlize those two and will get the embeddings for each sentence in the \n",
    "Train and test data.</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L8MhaxTW3IOC",
    "outputId": "c032e6b8-f6af-4ad3-9233-0c7e5e7c6da5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 101, 2122, 3653, ...,    0,    0,    0],\n",
       "       [ 101, 2023, 5474, ...,    0,    0,    0],\n",
       "       [ 101, 1996, 2194, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 101, 1045, 1005, ...,    0,    0,    0],\n",
       "       [ 101, 2074, 1037, ...,    0,    0,    0],\n",
       "       [ 101, 2074, 1037, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QwOVgQFDqVBy",
    "outputId": "19d920c9-790d-47e9-f22f-e6da4f82490f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 55) dtype=int32 (created by layer 'input_word_ids')>,\n",
       " <KerasTensor: shape=(None, 55) dtype=int32 (created by layer 'input_mask')>,\n",
       " <KerasTensor: shape=(None, 55) dtype=int32 (created by layer 'segment_ids')>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZcpkQq1OqVB0",
    "outputId": "920a3eee-9d29-43a4-c148-af4aea625210"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'keras_layer')>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "IxdIlOIBlm7j"
   },
   "outputs": [],
   "source": [
    "# get the train output, BERT model will give one output so save in\n",
    "# X_train_pooled_output\n",
    "X_train_pooled_output = bert_model.predict([X_train_tokens,X_train_mask,X_train_segment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "yZT11BCol4gL"
   },
   "outputs": [],
   "source": [
    "# get the test output, BERT model will give one output so save in\n",
    "# X_test_pooled_output\n",
    "X_test_pooled_output =bert_model.predict([X_test_tokens,X_test_mask,X_test_segment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DL6JVojfqVB8"
   },
   "outputs": [],
   "source": [
    "  ##save all your results to disk so that, no need to run all again. \n",
    "import pickle\n",
    "pickle.dump((X_train_pooled_output, X_test_pooled_output),open('final_output.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oSQcBdROqVB9"
   },
   "outputs": [],
   "source": [
    "#X_train_pooled_output, X_test_pooled_output= pickle.load(open('final_output.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulEXFE7aqVCA"
   },
   "source": [
    "<font size=4>Grader function 6 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oHCsW0IvqVCB",
    "outputId": "caa26064-53bd-460a-e31c-af3cfa407d7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we have X_train_pooled_output, y_train\n",
    "#X_test_pooled_ouput, y_test\n",
    "\n",
    "#please use this grader to evaluate\n",
    "def greader_output():\n",
    "    assert(X_train_pooled_output.shape[1]==768)\n",
    "    assert(len(y_train)==len(X_train_pooled_output))\n",
    "    assert(X_test_pooled_output.shape[1]==768)\n",
    "    assert(len(y_test)==len(X_test_pooled_output))\n",
    "    assert(len(y_train.shape)==1)\n",
    "    assert(len(X_train_pooled_output.shape)==2)\n",
    "    assert(len(y_test.shape)==1)\n",
    "    assert(len(X_test_pooled_output.shape)==2)\n",
    "    return True\n",
    "greader_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYwS1QbAqVCD"
   },
   "source": [
    "<pre><font size=6>Part-5: Training a NN with 768 features</font>\n",
    "\n",
    "Create a NN and train the NN. \n",
    "1.<b> You have to use AUC as metric.</b> \n",
    "2. You can use any architecture you want. \n",
    "3. You have to use tensorboard to log all your metrics and Losses. You have to send those logs. \n",
    "4. Print the loss and metric at every epoch. \n",
    "5. You have to submit without overfitting and underfitting. \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "od8PQlYRqVCE"
   },
   "outputs": [],
   "source": [
    "##imports\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DSnmX3WnqVCG",
    "outputId": "0272e590-f87e-444b-fcc5-e506afbd2064"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##create an NN and \n",
    "X_train_pooled_output.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ZBA8p0UZi8K",
    "outputId": "0c90a9ab-8937-4cfe-a99e-ab731cf7383d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 768)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               196864    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 238,081\n",
      "Trainable params: 238,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(50)\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "input_layer = Input(shape=X_train_pooled_output.shape[1])\n",
    "dense_layer_4 = Dense(256, activation='relu')(input_layer)\n",
    "dense_layer_5 = Dense(128, activation='relu')(dense_layer_4)\n",
    "dense_layer_6 = Dense(64, activation='relu')(dense_layer_5)\n",
    "Output_layer = Dense(1,activation = 'sigmoid')(dense_layer_6)\n",
    "model = Model(inputs = input_layer, outputs = Output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ySpjS-o2LTV1"
   },
   "outputs": [],
   "source": [
    "filepath=\"best_model-{epoch:02d}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_auc_score',  verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ldiKBW06nWCs"
   },
   "outputs": [],
   "source": [
    "#custom AUC metric\n",
    "#https://stackoverflow.com/questions/41032551/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras\n",
    "from sklearn.metrics import roc_auc_score\n",
    "class RocCallback(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, training_data,validation_data):\n",
    "        #super(AUC, self).__init__()\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        ## on begin of training, we are creating a instance varible called history\n",
    "        ## it is a dict with keys [loss, acc, val_loss, val_acc]\n",
    "        self.history={'loss': [],'accuracy': [],'AUC': []}\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "     \n",
    "        y_pred_train = self.model.predict(self.x)\n",
    "        roc_train = roc_auc_score(self.y, y_pred_train)\n",
    "        y_pred_val = self.model.predict(self.x_val)\n",
    "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "        print('\\rroc-auc_train: %s - roc-auc_val: %s' % (str(round(roc_train,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n",
    "        # if(roc_val > 0.95): \n",
    "        #   print(\"Got it\")   \n",
    "        #   self.model.stop_training = True\n",
    "\n",
    "        #print(' AUC:{}'.format(val_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Ur5KwbLac-qy"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from keras.callbacks import TensorBoard\n",
    "!rm -rf ./logs/ \n",
    "logdir = \"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "tensorboard = TensorBoard(log_dir=logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "ak_ElrfRqOy6"
   },
   "outputs": [],
   "source": [
    "roc = RocCallback(training_data=(X_train_pooled_output, y_train),\n",
    "                  validation_data=(X_test_pooled_output, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "09pj_t5nRKeX"
   },
   "outputs": [],
   "source": [
    "# from tensorflow.python.keras.callbacks import ReduceLROnPlateau\n",
    "# lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "#                               patience=2,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NkHwEW_6dAW8",
    "outputId": "aaa24ce5-c55c-41a7-98e9-d17a08c9b5eb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   3/1250 [..............................] - ETA: 2:16 - loss: 0.7641 - accuracy: 0.1615WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0029s vs `on_train_batch_begin` time: 0.0180s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0029s vs `on_train_batch_begin` time: 0.0180s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_train_batch_end` time: 0.0183s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_train_batch_end` time: 0.0183s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.3597 - accuracy: 0.8672 - val_loss: 0.3289 - val_accuracy: 0.8707\n",
      "roc-auc_train: 0.797 - roc-auc_val: 0.7912                                                                                                    \n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.3096 - accuracy: 0.8761 - val_loss: 0.2946 - val_accuracy: 0.8838\n",
      "roc-auc_train: 0.8357 - roc-auc_val: 0.8325                                                                                                    \n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.2867 - accuracy: 0.8857 - val_loss: 0.2787 - val_accuracy: 0.8885\n",
      "roc-auc_train: 0.8498 - roc-auc_val: 0.8469                                                                                                    \n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.2755 - accuracy: 0.8921 - val_loss: 0.2770 - val_accuracy: 0.9001\n",
      "roc-auc_train: 0.8551 - roc-auc_val: 0.8519                                                                                                    \n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.2687 - accuracy: 0.8971 - val_loss: 0.2650 - val_accuracy: 0.9000\n",
      "roc-auc_train: 0.8592 - roc-auc_val: 0.8556                                                                                                    \n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.2642 - accuracy: 0.8996 - val_loss: 0.2632 - val_accuracy: 0.9042\n",
      "roc-auc_train: 0.8613 - roc-auc_val: 0.8572                                                                                                    \n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2616 - accuracy: 0.9012 - val_loss: 0.2593 - val_accuracy: 0.9039\n",
      "roc-auc_train: 0.8636 - roc-auc_val: 0.8587                                                                                                    \n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.2587 - accuracy: 0.9026 - val_loss: 0.2571 - val_accuracy: 0.9054\n",
      "roc-auc_train: 0.8648 - roc-auc_val: 0.8599                                                                                                    \n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.2575 - accuracy: 0.9035 - val_loss: 0.2576 - val_accuracy: 0.9064\n",
      "roc-auc_train: 0.8658 - roc-auc_val: 0.8608                                                                                                    \n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2559 - accuracy: 0.9039 - val_loss: 0.2567 - val_accuracy: 0.9039\n",
      "roc-auc_train: 0.8666 - roc-auc_val: 0.8617                                                                                                    \n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=2e-5),\n",
    "loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
    "model2 = model.fit(X_train_pooled_output, y_train,validation_data = (X_test_pooled_output, y_test), epochs=10,batch_size=64,verbose=1,callbacks=[tensorboard,roc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "35vs_XLKItJa",
    "outputId": "0e7e13e6-c848-4644-e9a9-cc7ab865c28a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(model2.history['accuracy'])\n",
    "plt.plot(model2.history['val_accuracy'])\n",
    "plt.title(\"accuracy\") \n",
    "plt.xlabel(\"epoch\") \n",
    "plt.ylabel(\"accuracy\") \n",
    "plt.legend(['train','validation']) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcILeYZI9pxm"
   },
   "source": [
    "<Pre><font size=6>Part-6: Creating a Data pipeline for BERT Model</font> \n",
    "\n",
    "1. Download data from <a href=\"https://drive.google.com/file/d/1QwjqTsqTX2vdy7fTmeXjxP3dq8IAVLpo/view?usp=sharing\">here</a>\n",
    "2. Read the csv file\n",
    "3. Remove all the html tags\n",
    "4. Now do tokenization [Part 3 as mentioned above]\n",
    "    * Create tokens,mask array and segment array\n",
    "5. Get Embeddings from BERT Model [Part 4 as mentioned above] , let it be X_test\n",
    "   * Print the shape of output(X_test.shape).You should get (352,768)\n",
    "6. Predit the output of X_test with the Neural network model which we trained earlier.\n",
    "7. Print the occurences of class labels in the predicted output\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8hGAHApL_jqJ",
    "outputId": "a2d32674-6011-4fbf-ff70-b0141bd0c422"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1QwjqTsqTX2vdy7fTmeXjxP3dq8IAVLpo\n",
      "To: /content/test.csv\n",
      "\r",
      "  0% 0.00/62.1k [00:00<?, ?B/s]\r",
      "100% 62.1k/62.1k [00:00<00:00, 54.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 1QwjqTsqTX2vdy7fTmeXjxP3dq8IAVLpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iiBeOnna9yDH",
    "outputId": "d0001d35-ee2b-4d3f-cbb9-03e79241c63d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 352 entries, 0 to 351\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Text    352 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 2.9+ KB\n"
     ]
    }
   ],
   "source": [
    "test_set = pd.read_csv(r\"test.csv\")\n",
    "#check the info of the dataset\n",
    "test_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "wvLqSCyX_v-V",
    "outputId": "e5d02c4f-b756-4bdd-995a-7ad41c9b5f16"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just opened Greenies Joint Care (individually ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This product rocks :) My mom was very happy w/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The product was fine, but the cost of shipping...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I love this soup. It's great as part of a meal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Getting ready to order again. These are great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>Without a doubt this is by far the BEST beef g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>My 8 month old loves these. He hardly swallows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>the flavor palet for this coffee is deep and r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>This is the best granola my family has ever ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>This tea and it's sister products from Numi gi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>352 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text\n",
       "0    Just opened Greenies Joint Care (individually ...\n",
       "1    This product rocks :) My mom was very happy w/...\n",
       "2    The product was fine, but the cost of shipping...\n",
       "3    I love this soup. It's great as part of a meal...\n",
       "4    Getting ready to order again. These are great ...\n",
       "..                                                 ...\n",
       "347  Without a doubt this is by far the BEST beef g...\n",
       "348  My 8 month old loves these. He hardly swallows...\n",
       "349  the flavor palet for this coffee is deep and r...\n",
       "350  This is the best granola my family has ever ha...\n",
       "351  This tea and it's sister products from Numi gi...\n",
       "\n",
       "[352 rows x 1 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8QDeZak6_xm6",
    "outputId": "827517ee-5d34-41e9-a5a4-f1df3a6a845a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 352/352 [00:00<00:00, 1416.39it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_id_test_set = []\n",
    "padded_list_test_set = []\n",
    "segment_list_test_set = []\n",
    "for review in tqdm((test_set['Text'])):\n",
    "        tokens = tokenizer.tokenize(review)\n",
    "        tokens = ['[CLS]', *tokens, '[SEP]']\n",
    "        # ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        # ids = [ int(x) for x in ids ]\n",
    "        # tokenized_id_test.append(ids)\n",
    "        if len(tokens)<=max_seq_length: \n",
    "          #padding with [PAD]\n",
    "            padded = tokens+['[PAD]' for i in range(max_seq_length - len(tokens))]\n",
    "        ids = tokenizer.convert_tokens_to_ids(padded)\n",
    "        ids = [ int(x) for x in ids ]\n",
    "        padded_list_test_set.append(ids)\n",
    "        segment = np.zeros(max_seq_length, dtype = int)\n",
    "        segment_list_test_set.append(segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "agCjesj8AYGR"
   },
   "outputs": [],
   "source": [
    "attention_mask_test_set = np.where(np.array(padded_list_test_set) != [0], 1, 0)\n",
    "X_test_tokens_set, X_test_mask_set, X_test_segment_set = np.array(padded_list_test_set),np.array(attention_mask_test_set),np.array(segment_list_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "JeHq0hcTA0cT"
   },
   "outputs": [],
   "source": [
    "X_test_pooled_output_set = bert_model.predict([X_test_tokens_set,X_test_mask_set,X_test_segment_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "wVwNoKZ0BAP_"
   },
   "outputs": [],
   "source": [
    "\n",
    "prob = model.predict(X_test_pooled_output_set)\n",
    "if prob.shape[-1] > 1:\n",
    "   result = prob.argmax(axis=-1)\n",
    "else:\n",
    "  result = (prob > 0.5).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "olEFmLyUBEz1",
    "outputId": "280ab7ef-045f-47c4-8d4d-84062fc5486b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    328\n",
       "0     24\n",
       "Name: Result, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = pd.DataFrame(data=prob,columns=['Prob_score'])\n",
    "prediction['Result'] = result\n",
    "prediction['Result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "ZVvuBElvfVaP",
    "outputId": "480f4646-2156-4323-e897-41ae207006d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prob_score</th>\n",
       "      <th>Result</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.396946</td>\n",
       "      <td>0</td>\n",
       "      <td>Just opened Greenies Joint Care (individually ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.963675</td>\n",
       "      <td>1</td>\n",
       "      <td>This product rocks :) My mom was very happy w/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.768440</td>\n",
       "      <td>1</td>\n",
       "      <td>The product was fine, but the cost of shipping...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.886539</td>\n",
       "      <td>1</td>\n",
       "      <td>I love this soup. It's great as part of a meal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.886539</td>\n",
       "      <td>1</td>\n",
       "      <td>Getting ready to order again. These are great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0.658051</td>\n",
       "      <td>1</td>\n",
       "      <td>Without a doubt this is by far the BEST beef g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0.973695</td>\n",
       "      <td>1</td>\n",
       "      <td>My 8 month old loves these. He hardly swallows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>0.943045</td>\n",
       "      <td>1</td>\n",
       "      <td>the flavor palet for this coffee is deep and r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>0.943045</td>\n",
       "      <td>1</td>\n",
       "      <td>This is the best granola my family has ever ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>0.980773</td>\n",
       "      <td>1</td>\n",
       "      <td>This tea and it's sister products from Numi gi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>352 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Prob_score  Result                                               text\n",
       "0      0.396946       0  Just opened Greenies Joint Care (individually ...\n",
       "1      0.963675       1  This product rocks :) My mom was very happy w/...\n",
       "2      0.768440       1  The product was fine, but the cost of shipping...\n",
       "3      0.886539       1  I love this soup. It's great as part of a meal...\n",
       "4      0.886539       1  Getting ready to order again. These are great ...\n",
       "..          ...     ...                                                ...\n",
       "347    0.658051       1  Without a doubt this is by far the BEST beef g...\n",
       "348    0.973695       1  My 8 month old loves these. He hardly swallows...\n",
       "349    0.943045       1  the flavor palet for this coffee is deep and r...\n",
       "350    0.943045       1  This is the best granola my family has ever ha...\n",
       "351    0.980773       1  This tea and it's sister products from Numi gi...\n",
       "\n",
       "[352 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction['text'] = test_set['Text']\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ieMHvK7iOf8O"
   },
   "source": [
    "Here we are using  BERT base having 12 Encode bloacks  with 12 attention heads, and 110 million parameters\n",
    "\n",
    "Data preprocessing : \n",
    "We had done  Preprocessing of the text to remove HTML tags and converted the text into lowercase.\n",
    "\n",
    "Train test split and using pretrained BERT model to get embeddings:\n",
    "Split the data as train and test, startify as yes to maintain equal split among Target label. \n",
    "\n",
    "Inorder to use BERT model we need  to give \n",
    "  \n",
    "   Input of word as token\n",
    "  \n",
    "   Masking \n",
    "  \n",
    "   Segement  \n",
    "When we give these inputs we are getting\n",
    "pooled_output -  representation of [batch_size, 768]  \n",
    "and sequence_output [batch_size, max_seq_length, 768]  \n",
    "\n",
    "For classification we are using NN with RELU activation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-5AtN_CBP0Q0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy_of_BERT_Assignment_(2).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
